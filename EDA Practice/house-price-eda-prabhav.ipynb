{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5407,"databundleVersionId":868283,"sourceType":"competition"},{"sourceId":8558476,"sourceType":"datasetVersion","datasetId":5115198}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-31T02:55:33.031171Z","iopub.execute_input":"2024-05-31T02:55:33.031669Z","iopub.status.idle":"2024-05-31T02:55:34.214828Z","shell.execute_reply.started":"2024-05-31T02:55:33.031624Z","shell.execute_reply":"2024-05-31T02:55:34.213666Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/house-prices-advanced-regression-techniques/sample_submission.csv\n/kaggle/input/house-prices-advanced-regression-techniques/data_description.txt\n/kaggle/input/house-prices-advanced-regression-techniques/train.csv\n/kaggle/input/house-prices-advanced-regression-techniques/test.csv\n/kaggle/input/house-dataset-variable-desc/House Price Dataset.xlsx\n","output_type":"stream"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.stats import norm\nfrom sklearn.preprocessing import StandardScaler\nfrom scipy import stats\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline \n#this allows to show plot in output cell without the use of plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-31T02:55:34.217016Z","iopub.execute_input":"2024-05-31T02:55:34.217781Z","iopub.status.idle":"2024-05-31T02:55:35.992858Z","shell.execute_reply.started":"2024-05-31T02:55:34.217748Z","shell.execute_reply":"2024-05-31T02:55:35.991599Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/train.csv')","metadata":{"execution":{"iopub.status.busy":"2024-05-31T02:55:35.994495Z","iopub.execute_input":"2024-05-31T02:55:35.994979Z","iopub.status.idle":"2024-05-31T02:55:36.058342Z","shell.execute_reply.started":"2024-05-31T02:55:35.994936Z","shell.execute_reply":"2024-05-31T02:55:36.057354Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"!pip install ydata-profiling","metadata":{"execution":{"iopub.status.busy":"2024-05-31T03:07:36.015812Z","iopub.execute_input":"2024-05-31T03:07:36.016327Z","iopub.status.idle":"2024-05-31T03:07:53.975527Z","shell.execute_reply.started":"2024-05-31T03:07:36.016281Z","shell.execute_reply":"2024-05-31T03:07:53.973983Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Requirement already satisfied: ydata-profiling in /opt/conda/lib/python3.10/site-packages (4.6.4)\nRequirement already satisfied: scipy<1.12,>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from ydata-profiling) (1.11.4)\nRequirement already satisfied: pandas!=1.4.0,<3,>1.1 in /opt/conda/lib/python3.10/site-packages (from ydata-profiling) (2.2.2)\nRequirement already satisfied: matplotlib<3.9,>=3.2 in /opt/conda/lib/python3.10/site-packages (from ydata-profiling) (3.7.5)\nCollecting pydantic>=2 (from ydata-profiling)\n  Downloading pydantic-2.7.2-py3-none-any.whl.metadata (108 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.5/108.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: PyYAML<6.1,>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from ydata-profiling) (6.0.1)\nRequirement already satisfied: jinja2<3.2,>=2.11.1 in /opt/conda/lib/python3.10/site-packages (from ydata-profiling) (3.1.2)\nRequirement already satisfied: visions==0.7.5 in /opt/conda/lib/python3.10/site-packages (from visions[type_image_path]==0.7.5->ydata-profiling) (0.7.5)\nRequirement already satisfied: numpy<1.26,>=1.16.0 in /opt/conda/lib/python3.10/site-packages (from ydata-profiling) (1.25.2)\nRequirement already satisfied: htmlmin==0.1.12 in /opt/conda/lib/python3.10/site-packages (from ydata-profiling) (0.1.12)\nRequirement already satisfied: phik<0.13,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from ydata-profiling) (0.12.4)\nRequirement already satisfied: requests<3,>=2.24.0 in /opt/conda/lib/python3.10/site-packages (from ydata-profiling) (2.31.0)\nRequirement already satisfied: tqdm<5,>=4.48.2 in /opt/conda/lib/python3.10/site-packages (from ydata-profiling) (4.66.1)\nRequirement already satisfied: seaborn<0.13,>=0.10.1 in /opt/conda/lib/python3.10/site-packages (from ydata-profiling) (0.12.2)\nRequirement already satisfied: multimethod<2,>=1.4 in /opt/conda/lib/python3.10/site-packages (from ydata-profiling) (1.10)\nRequirement already satisfied: statsmodels<1,>=0.13.2 in /opt/conda/lib/python3.10/site-packages (from ydata-profiling) (0.14.1)\nRequirement already satisfied: typeguard<5,>=4.1.2 in /opt/conda/lib/python3.10/site-packages (from ydata-profiling) (4.1.5)\nRequirement already satisfied: imagehash==4.3.1 in /opt/conda/lib/python3.10/site-packages (from ydata-profiling) (4.3.1)\nRequirement already satisfied: wordcloud>=1.9.1 in /opt/conda/lib/python3.10/site-packages (from ydata-profiling) (1.9.3)\nRequirement already satisfied: dacite>=1.8 in /opt/conda/lib/python3.10/site-packages (from ydata-profiling) (1.8.1)\nRequirement already satisfied: numba<0.59.0,>=0.56.0 in /opt/conda/lib/python3.10/site-packages (from ydata-profiling) (0.58.1)\nRequirement already satisfied: PyWavelets in /opt/conda/lib/python3.10/site-packages (from imagehash==4.3.1->ydata-profiling) (1.5.0)\nRequirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from imagehash==4.3.1->ydata-profiling) (9.5.0)\nRequirement already satisfied: attrs>=19.3.0 in /opt/conda/lib/python3.10/site-packages (from visions==0.7.5->visions[type_image_path]==0.7.5->ydata-profiling) (23.2.0)\nRequirement already satisfied: networkx>=2.4 in /opt/conda/lib/python3.10/site-packages (from visions==0.7.5->visions[type_image_path]==0.7.5->ydata-profiling) (3.2.1)\nRequirement already satisfied: tangled-up-in-unicode>=0.0.4 in /opt/conda/lib/python3.10/site-packages (from visions==0.7.5->visions[type_image_path]==0.7.5->ydata-profiling) (0.2.0)\n\u001b[33mWARNING: visions 0.7.5 does not provide the extra 'type-image-path'\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2<3.2,>=2.11.1->ydata-profiling) (2.1.3)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib<3.9,>=3.2->ydata-profiling) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib<3.9,>=3.2->ydata-profiling) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib<3.9,>=3.2->ydata-profiling) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib<3.9,>=3.2->ydata-profiling) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib<3.9,>=3.2->ydata-profiling) (21.3)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib<3.9,>=3.2->ydata-profiling) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib<3.9,>=3.2->ydata-profiling) (2.9.0.post0)\nRequirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba<0.59.0,>=0.56.0->ydata-profiling) (0.41.1)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas!=1.4.0,<3,>1.1->ydata-profiling) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas!=1.4.0,<3,>1.1->ydata-profiling) (2023.4)\nRequirement already satisfied: joblib>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from phik<0.13,>=0.11.1->ydata-profiling) (1.4.0)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2->ydata-profiling) (0.6.0)\nCollecting pydantic-core==2.18.3 (from pydantic>=2->ydata-profiling)\n  Downloading pydantic_core-2.18.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\nRequirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2->ydata-profiling) (4.9.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.24.0->ydata-profiling) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.24.0->ydata-profiling) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.24.0->ydata-profiling) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.24.0->ydata-profiling) (2024.2.2)\nRequirement already satisfied: patsy>=0.5.4 in /opt/conda/lib/python3.10/site-packages (from statsmodels<1,>=0.13.2->ydata-profiling) (0.5.6)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from patsy>=0.5.4->statsmodels<1,>=0.13.2->ydata-profiling) (1.16.0)\nDownloading pydantic-2.7.2-py3-none-any.whl (409 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.5/409.5 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pydantic_core-2.18.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pydantic-core, pydantic\n  Attempting uninstall: pydantic-core\n    Found existing installation: pydantic_core 2.14.6\n    Uninstalling pydantic_core-2.14.6:\n      Successfully uninstalled pydantic_core-2.14.6\n  Attempting uninstall: pydantic\n    Found existing installation: pydantic 1.10.7\n    Uninstalling pydantic-1.10.7:\n      Successfully uninstalled pydantic-1.10.7\nSuccessfully installed pydantic-2.7.2 pydantic-core-2.18.3\n","output_type":"stream"}]},{"cell_type":"code","source":"from ydata_profiling import ProfileReport\nprofile = ProfileReport(data)\nprofile.to_file('HousePriceProfileReport.html')","metadata":{"execution":{"iopub.status.busy":"2024-05-31T03:08:45.832203Z","iopub.execute_input":"2024-05-31T03:08:45.832754Z","iopub.status.idle":"2024-05-31T03:15:37.228065Z","shell.execute_reply.started":"2024-05-31T03:08:45.832705Z","shell.execute_reply":"2024-05-31T03:15:37.225801Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5509bba92434316bf21640934ad0088"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"083946ed11274e05a94f24ea029c250a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f391db877a14325b908aa76837039e4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48ecdf8b22334c1781661a5e46d4ed2a"}},"metadata":{}}]},{"cell_type":"code","source":"data.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-05-30T11:14:51.859743Z","iopub.execute_input":"2024-05-30T11:14:51.860116Z","iopub.status.idle":"2024-05-30T11:14:51.892136Z","shell.execute_reply.started":"2024-05-30T11:14:51.860085Z","shell.execute_reply":"2024-05-30T11:14:51.890690Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.columns","metadata":{"execution":{"iopub.status.busy":"2024-05-30T11:14:51.893704Z","iopub.execute_input":"2024-05-30T11:14:51.894108Z","iopub.status.idle":"2024-05-30T11:14:51.907041Z","shell.execute_reply.started":"2024-05-30T11:14:51.894077Z","shell.execute_reply":"2024-05-30T11:14:51.905800Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Add the variables study excel sheet here\nvar_study = pd.read_excel('/kaggle/input/house-dataset-variable-desc/House Price Dataset.xlsx')\nvar_study","metadata":{"execution":{"iopub.status.busy":"2024-05-30T11:14:51.908631Z","iopub.execute_input":"2024-05-30T11:14:51.909100Z","iopub.status.idle":"2024-05-30T11:14:51.961751Z","shell.execute_reply.started":"2024-05-30T11:14:51.909067Z","shell.execute_reply":"2024-05-30T11:14:51.960001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['MSSubClass'].nunique()","metadata":{"execution":{"iopub.status.busy":"2024-05-30T11:14:51.963074Z","iopub.execute_input":"2024-05-30T11:14:51.963425Z","iopub.status.idle":"2024-05-30T11:14:51.971373Z","shell.execute_reply.started":"2024-05-30T11:14:51.963392Z","shell.execute_reply":"2024-05-30T11:14:51.970321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['LowQualFinSF'].unique()","metadata":{"execution":{"iopub.status.busy":"2024-05-30T11:14:51.972801Z","iopub.execute_input":"2024-05-30T11:14:51.973131Z","iopub.status.idle":"2024-05-30T11:14:51.987985Z","shell.execute_reply.started":"2024-05-30T11:14:51.973103Z","shell.execute_reply":"2024-05-30T11:14:51.986616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['KitchenAbvGr'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-05-30T11:14:51.993010Z","iopub.execute_input":"2024-05-30T11:14:51.993411Z","iopub.status.idle":"2024-05-30T11:14:52.003772Z","shell.execute_reply.started":"2024-05-30T11:14:51.993380Z","shell.execute_reply":"2024-05-30T11:14:52.002589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***Analysing SalePrice***","metadata":{}},{"cell_type":"code","source":"data['SalePrice'].describe()","metadata":{"execution":{"iopub.status.busy":"2024-05-30T11:14:52.005900Z","iopub.execute_input":"2024-05-30T11:14:52.006422Z","iopub.status.idle":"2024-05-30T11:14:52.024701Z","shell.execute_reply.started":"2024-05-30T11:14:52.006374Z","shell.execute_reply":"2024-05-30T11:14:52.023066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['SalePrice'].isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2024-05-30T11:14:52.026256Z","iopub.execute_input":"2024-05-30T11:14:52.026768Z","iopub.status.idle":"2024-05-30T11:14:52.039076Z","shell.execute_reply.started":"2024-05-30T11:14:52.026611Z","shell.execute_reply":"2024-05-30T11:14:52.037734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['SalePrice'].nunique()","metadata":{"execution":{"iopub.status.busy":"2024-05-30T11:14:52.040833Z","iopub.execute_input":"2024-05-30T11:14:52.041307Z","iopub.status.idle":"2024-05-30T11:14:52.059064Z","shell.execute_reply.started":"2024-05-30T11:14:52.041266Z","shell.execute_reply":"2024-05-30T11:14:52.057691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['SalePrice'].duplicated().sum()","metadata":{"execution":{"iopub.status.busy":"2024-05-30T11:14:52.061104Z","iopub.execute_input":"2024-05-30T11:14:52.061572Z","iopub.status.idle":"2024-05-30T11:14:52.074279Z","shell.execute_reply.started":"2024-05-30T11:14:52.061530Z","shell.execute_reply":"2024-05-30T11:14:52.072840Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mod = data['SalePrice'].mode()\nprint(mod)","metadata":{"execution":{"iopub.status.busy":"2024-05-30T11:14:52.075892Z","iopub.execute_input":"2024-05-30T11:14:52.076226Z","iopub.status.idle":"2024-05-30T11:14:52.087606Z","shell.execute_reply.started":"2024-05-30T11:14:52.076197Z","shell.execute_reply":"2024-05-30T11:14:52.086504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['SalePrice'].value_counts()[mod]","metadata":{"execution":{"iopub.status.busy":"2024-05-30T11:14:52.088956Z","iopub.execute_input":"2024-05-30T11:14:52.089288Z","iopub.status.idle":"2024-05-30T11:14:52.107966Z","shell.execute_reply.started":"2024-05-30T11:14:52.089259Z","shell.execute_reply":"2024-05-30T11:14:52.106681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.hist(data['SalePrice'], bins=30)","metadata":{"execution":{"iopub.status.busy":"2024-05-30T11:14:52.109588Z","iopub.execute_input":"2024-05-30T11:14:52.110085Z","iopub.status.idle":"2024-05-30T11:14:52.542261Z","shell.execute_reply.started":"2024-05-30T11:14:52.110043Z","shell.execute_reply":"2024-05-30T11:14:52.540980Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.boxplot(x='SalePrice', data=data)","metadata":{"execution":{"iopub.status.busy":"2024-05-30T11:14:52.543978Z","iopub.execute_input":"2024-05-30T11:14:52.544436Z","iopub.status.idle":"2024-05-30T11:14:52.909295Z","shell.execute_reply.started":"2024-05-30T11:14:52.544395Z","shell.execute_reply":"2024-05-30T11:14:52.908074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.distplot(data['SalePrice'])","metadata":{"execution":{"iopub.status.busy":"2024-05-30T11:14:52.911086Z","iopub.execute_input":"2024-05-30T11:14:52.911548Z","iopub.status.idle":"2024-05-30T11:14:53.433145Z","shell.execute_reply.started":"2024-05-30T11:14:52.911509Z","shell.execute_reply":"2024-05-30T11:14:53.431928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(data['SalePrice'].skew())\nprint(data['SalePrice'].kurt())","metadata":{"execution":{"iopub.status.busy":"2024-05-30T11:14:53.434790Z","iopub.execute_input":"2024-05-30T11:14:53.435249Z","iopub.status.idle":"2024-05-30T11:14:53.443066Z","shell.execute_reply.started":"2024-05-30T11:14:53.435207Z","shell.execute_reply":"2024-05-30T11:14:53.441888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"CONCLUSIONS:\n* Doesn't follow a normal distribution, right/+ve skewed\n* Peak is there","metadata":{}},{"cell_type":"markdown","source":"> ***Analysing SalePrice with other variables***","metadata":{}},{"cell_type":"code","source":"# Studying only variables which seem to have high impact\n# according to intuition\n# - GrLivArea\n# - TotalBsmtSF\n# - OverallQual\n# - YearBuilt","metadata":{"execution":{"iopub.status.busy":"2024-05-30T11:14:53.444451Z","iopub.execute_input":"2024-05-30T11:14:53.444842Z","iopub.status.idle":"2024-05-30T11:14:53.458073Z","shell.execute_reply.started":"2024-05-30T11:14:53.444810Z","shell.execute_reply":"2024-05-30T11:14:53.456942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#scatter plot grlivarea/saleprice\n# sns.relplot(x='GrLivArea', y='SalePrice', kind='scatter', data=data)\nsns.lmplot(x='GrLivArea', y='SalePrice', data=data)","metadata":{"execution":{"iopub.status.busy":"2024-05-30T11:14:53.459713Z","iopub.execute_input":"2024-05-30T11:14:53.460190Z","iopub.status.idle":"2024-05-30T11:14:54.422121Z","shell.execute_reply.started":"2024-05-30T11:14:53.460144Z","shell.execute_reply":"2024-05-30T11:14:54.420919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#scatter plot totalbsmtsf/saleprice\nsns.relplot(x='TotalBsmtSF', y='SalePrice', data=data)","metadata":{"execution":{"iopub.status.busy":"2024-05-30T11:14:54.423768Z","iopub.execute_input":"2024-05-30T11:14:54.424149Z","iopub.status.idle":"2024-05-30T11:14:55.187200Z","shell.execute_reply.started":"2024-05-30T11:14:54.424117Z","shell.execute_reply":"2024-05-30T11:14:55.186019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#box plot overallqual/saleprice\nsns.boxplot(x='OverallQual', y='SalePrice', data=data)","metadata":{"execution":{"iopub.status.busy":"2024-05-30T11:14:55.189189Z","iopub.execute_input":"2024-05-30T11:14:55.189817Z","iopub.status.idle":"2024-05-30T11:14:55.724172Z","shell.execute_reply.started":"2024-05-30T11:14:55.189767Z","shell.execute_reply":"2024-05-30T11:14:55.722908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots()\nsns.distplot(x=data[data['OverallQual']==1]['SalePrice'], hist=False, label='1')\nsns.distplot(x=data[data['OverallQual']==2]['SalePrice'], hist=False, label='2')\nsns.distplot(x=data[data['OverallQual']==3]['SalePrice'], hist=False, label='3')\nsns.distplot(x=data[data['OverallQual']==4]['SalePrice'], hist=False, label='4')\nsns.distplot(x=data[data['OverallQual']==5]['SalePrice'], hist=False, label='5')\nsns.distplot(x=data[data['OverallQual']==6]['SalePrice'], hist=False, label='6')\nsns.distplot(x=data[data['OverallQual']==7]['SalePrice'], hist=False, label='7')\nsns.distplot(x=data[data['OverallQual']==8]['SalePrice'], hist=False, label='8')\nsns.distplot(x=data[data['OverallQual']==9]['SalePrice'], hist=False, label='9')\nsns.distplot(x=data[data['OverallQual']==10]['SalePrice'], hist=False, label='10')\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2024-05-30T11:14:55.726045Z","iopub.execute_input":"2024-05-30T11:14:55.726437Z","iopub.status.idle":"2024-05-30T11:14:56.640475Z","shell.execute_reply.started":"2024-05-30T11:14:55.726405Z","shell.execute_reply":"2024-05-30T11:14:56.639015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Create a FacetGrid\ng = sns.FacetGrid(data, hue=\"OverallQual\", aspect=2, height=5)\n\n# Map the kdeplot onto the grid\ng.map(sns.kdeplot, \"SalePrice\", common_norm=False)\n\n# Add a legend\ng.add_legend(title='OverallQual')\n\n# Show the plot\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-30T11:14:56.642203Z","iopub.execute_input":"2024-05-30T11:14:56.642771Z","iopub.status.idle":"2024-05-30T11:14:57.824916Z","shell.execute_reply.started":"2024-05-30T11:14:56.642727Z","shell.execute_reply":"2024-05-30T11:14:57.823729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#box plot yearbuilt/saleprice\nf, ax = plt.subplots(figsize=(16, 8))\nfig = sns.boxplot(x='YearBuilt', y=\"SalePrice\", data=data)\nfig.axis(ymin=0, ymax=800000);\nplt.xticks(rotation=90);","metadata":{"execution":{"iopub.status.busy":"2024-05-30T11:14:57.826558Z","iopub.execute_input":"2024-05-30T11:14:57.827023Z","iopub.status.idle":"2024-05-30T11:15:01.434978Z","shell.execute_reply.started":"2024-05-30T11:14:57.826980Z","shell.execute_reply":"2024-05-30T11:15:01.433658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Note: we don't know if 'SalePrice' is in constant prices. Constant prices try to remove the effect of inflation. If 'SalePrice' is not in constant prices, it should be, so than prices are comparable over the years.","metadata":{}},{"cell_type":"markdown","source":"CONCLUSIONS:\n* +ve Linear Relationship with GrLivArea\n* +ve Linear Relationship with TotalBsmtSF (higher slope)\n* Prices increased with a increase in OverallQual","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(12,9))\nsns.heatmap(data.corr(numeric_only=True), vmax=.8, square=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-30T11:15:01.441520Z","iopub.execute_input":"2024-05-30T11:15:01.441922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.corr(numeric_only=True)[['SalePrice']]","metadata":{"execution":{"iopub.status.busy":"2024-05-30T11:15:02.948428Z","iopub.execute_input":"2024-05-30T11:15:02.948906Z","iopub.status.idle":"2024-05-30T11:15:02.973841Z","shell.execute_reply.started":"2024-05-30T11:15:02.948864Z","shell.execute_reply":"2024-05-30T11:15:02.972612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"CONCLUSIONS:\n\n'TotalBsmtSF' and '1stFlrSF' & 'GarageX' variables are highly correlated.\n\nBoth cases show how significant the correlation is between these variables. Actually, this correlation is so strong that it can indicate a situation of multicollinearity. If we think about these variables, we can conclude that they give almost the same information so multicollinearity really occurs. Heatmaps are great to detect this kind of situations and in problems dominated by feature selection, like ours, they are an essential tool.","metadata":{}},{"cell_type":"code","source":"#saleprice correlation matrix\ncorrmat = data.corr(numeric_only=True)\n\n#number of variables for heatmap\nk=10 \n\n#This first sorts the table as per values of 'SalePrice' & \n#returns first 10 rows & then we store the names of those cols\ncols = corrmat.nlargest(k, 'SalePrice')['SalePrice'].index\n\n# Function: Computes the Pearson correlation coefficient matrix.\n# computes the correlation matrix of the rows (default behavior). \n# To compute the correlation matrix of the columns, you would need to transpose the array\n\ncm = np.corrcoef(data[cols].values.T)\n# cm = data[cols].corr() -> iske jaisa hi same kaam karega bas arrays output honge\n\nsns.set(font_scale=1)\n\nhm = sns.heatmap(cm, annot=True, square=True, fmt='.2f', \n                annot_kws={'size':10}, yticklabels=cols.values, \n                xticklabels=cols.values)\n# as array pass kara h toh xtick, ytick alag se batane padenge\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-30T11:15:02.975130Z","iopub.execute_input":"2024-05-30T11:15:02.975474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"CONCLUSIONS:\n* 'OverallQual', 'GrLivArea' and 'TotalBsmtSF' are strongly correlated with 'SalePrice'. \n* 'GarageCars' and 'GarageArea' are also some of the most strongly correlated variables. But, the number of cars that fit into the garage is a consequence of the garage area. 'GarageCars' and 'GarageArea' are like twin brothers. Therefore, we just need one of these variables in our analysis (we can keep 'GarageCars' since its correlation with 'SalePrice' is higher).\n* 'TotalBsmtSF' and '1stFloor' also seem to be twin brothers. We can keep 'TotalBsmtSF' just to say that our first guess was right\n* 'TotRmsAbvGrd' and 'GrLivArea', twin brothers again.\n* 'YearBuilt' is slightly correlated with 'SalePrice'. We should do a little bit of time-series analysis to get this right.","metadata":{}},{"cell_type":"code","source":"#scatterplot\nsns.set()\ncols = ['SalePrice', 'OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath', 'YearBuilt']\nsns.pairplot(data[cols], size = 2.5)\nplt.show();\ndata['SalePrice'].max()","metadata":{"execution":{"iopub.status.busy":"2024-05-30T11:15:03.722256Z","iopub.execute_input":"2024-05-30T11:15:03.722774Z","iopub.status.idle":"2024-05-30T11:15:20.310829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"One of the figures we may find interesting is the one between 'TotalBsmtSF' and 'GrLiveArea'. In this figure we can see the dots drawing a linear line, which almost acts like a border. It totally makes sense that the majority of the dots stay below that line. Basement areas can be equal to the above ground living area, but it is not expected a basement area bigger than the above ground living area (unless you're trying to buy a bunker).\n\nThe plot concerning 'SalePrice' and 'YearBuilt' can also make us think. In the bottom of the 'dots cloud', we see what almost appears to be a shy exponential function. We can also see this same tendency in the upper limit of the 'dots cloud'. Also, notice how the set of dots regarding the last years tend to stay above this limit (I just wanted to say that prices are increasing faster now).","metadata":{}},{"cell_type":"markdown","source":"> ***Missing Data***","metadata":{}},{"cell_type":"markdown","source":"Important questions when thinking about missing data:\n\n* How prevalent is the missing data?\n* Is missing data random or does it have a pattern?","metadata":{}},{"cell_type":"code","source":"total = data.isnull().sum().sort_values(ascending=False)\npercent = (data.isnull().sum()/data.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total','Percent'])\nmissing_data.head(20)","metadata":{"execution":{"iopub.status.busy":"2024-05-30T11:15:20.312548Z","iopub.execute_input":"2024-05-30T11:15:20.313656Z","iopub.status.idle":"2024-05-30T11:15:20.356392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We'll consider that when more than 15% of the data is missing, we should delete the corresponding variable. This means that we will not try any trick to fill the missing data in these cases.\n\nMoreover, looking closer at the variables, we could say that variables like 'PoolQC', 'MiscFeature' and 'FireplaceQu' are strong candidates for outliers, so we'll be happy to delete them.","metadata":{}},{"cell_type":"code","source":"# columns to be removed\nmissing_data[missing_data['Percent']>0.15].index","metadata":{"execution":{"iopub.status.busy":"2024-05-30T11:15:20.357860Z","iopub.execute_input":"2024-05-30T11:15:20.358223Z","iopub.status.idle":"2024-05-30T11:15:20.366778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that 'GarageX' variables have the same number of missing data. I bet missing data refers to the same set of observations. Since the most important information regarding garages is expressed by 'GarageCars' and considering that we are just talking about 5% of missing data, I'll delete the mentioned 'GarageX' variables. The same logic applies to 'BsmtX' variables.\n\nRegarding 'MasVnrArea' and 'MasVnrType', we can consider that these variables are not essential. Furthermore, they have a strong correlation with 'YearBuilt' and 'OverallQual' which are already considered. Thus, we will not lose information if we delete 'MasVnrArea' and 'MasVnrType'.\n\nFinally, we have one missing observation in 'Electrical'. Since it is just one observation, we'll delete this observation and keep the variable.\n\nIn summary, to handle missing data, we'll delete all the variables with missing data, except the variable 'Electrical'. In 'Electrical' we'll just delete the observation with missing data.","metadata":{}},{"cell_type":"code","source":"#dealing with missing data\ndata = data.drop((missing_data[missing_data['Total'] > 1]).index,axis=1)\ndata = data.drop(data.loc[data['Electrical'].isnull()].index)\ndata.isnull().sum().max()","metadata":{"execution":{"iopub.status.busy":"2024-05-30T11:15:20.368426Z","iopub.execute_input":"2024-05-30T11:15:20.368838Z","iopub.status.idle":"2024-05-30T11:15:20.396062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> ***Outliers***","metadata":{}},{"cell_type":"code","source":"# Univariate analysis\n# standardize the data - converting data values to have mean of\n# 0 and a standard deviation of 1\n\n#standardizing data\nsaleprice_scaled = StandardScaler().fit_transform(\n    data['SalePrice'].values.reshape(-1, 1));\nlow_range = saleprice_scaled[\n    saleprice_scaled[:,0].argsort()][:10]\nhigh_range= saleprice_scaled[\n    saleprice_scaled[:,0].argsort()][-10:]\n\nprint('outer range (low) of the distribution:')\nprint(low_range)\nprint('\\nouter range (high) of the distribution:')\nprint(high_range)","metadata":{"execution":{"iopub.status.busy":"2024-05-30T11:15:20.397541Z","iopub.execute_input":"2024-05-30T11:15:20.397991Z","iopub.status.idle":"2024-05-30T11:15:20.408873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.boxplot(saleprice_scaled)","metadata":{"execution":{"iopub.status.busy":"2024-05-30T11:15:20.410398Z","iopub.execute_input":"2024-05-30T11:15:20.411034Z","iopub.status.idle":"2024-05-30T11:15:20.657985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#For now not removing any outliers, but we should be careful with 7. values","metadata":{"execution":{"iopub.status.busy":"2024-05-30T11:15:20.659570Z","iopub.execute_input":"2024-05-30T11:15:20.660014Z","iopub.status.idle":"2024-05-30T11:15:20.664926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Bivariate analysis\n#bivariate analysis saleprice/grlivarea\nsns.relplot(x='GrLivArea', y='SalePrice', data=data, kind='scatter')","metadata":{"execution":{"iopub.status.busy":"2024-05-30T11:15:20.666277Z","iopub.execute_input":"2024-05-30T11:15:20.666596Z","iopub.status.idle":"2024-05-30T11:15:21.640929Z","shell.execute_reply.started":"2024-05-30T11:15:20.666568Z","shell.execute_reply":"2024-05-30T11:15:21.639699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"CONCLUSIONS:\n* The two values with bigger 'GrLivArea' seem strange and they are not following the crowd. Maybe they refer to agricultural area and that could explain the low price. These two points are not representative of the typical case. Therefore, we'll define them as outliers and delete them.\n* The two observations in the top of the plot are those 7.something observations. They look like two special cases, however they seem to be following the trend. For that reason, we will keep them.","metadata":{}},{"cell_type":"code","source":"#deleting points\ndata.sort_values(by='GrLivArea', ascending=False)[:2]","metadata":{"execution":{"iopub.status.busy":"2024-05-30T11:15:21.642763Z","iopub.execute_input":"2024-05-30T11:15:21.643215Z","iopub.status.idle":"2024-05-30T11:15:21.669895Z","shell.execute_reply.started":"2024-05-30T11:15:21.643181Z","shell.execute_reply":"2024-05-30T11:15:21.668700Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = data.drop(data[data['Id'] == 1299].index)\ndata = data.drop(data[data['Id'] == 524].index)","metadata":{"execution":{"iopub.status.busy":"2024-05-30T11:15:21.671280Z","iopub.execute_input":"2024-05-30T11:15:21.671614Z","iopub.status.idle":"2024-05-30T11:15:21.682511Z","shell.execute_reply.started":"2024-05-30T11:15:21.671582Z","shell.execute_reply":"2024-05-30T11:15:21.681294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#bivariate analysis saleprice/totalbsmtsf\nsns.relplot(x='TotalBsmtSF', y='SalePrice', data=data, kind='scatter')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can feel tempted to eliminate some observations (e.g. TotalBsmtSF > 3000) but I suppose it's not worth it. We can live with that, so we'll not do anything.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Time to go deep and understand how 'SalePrice' complies with the statistical assumptions that enables us to apply multivariate techniques.\n\nAccording to Hair et al. (2013), four assumptions should be tested:\n\n* **Normality** - the data should look like a normal distribution. This is important because several statistic tests rely on this (e.g. t-statistics). In this exercise we'll just check univariate normality for 'SalePrice' (which is a limited approach). Remember that univariate normality doesn't ensure multivariate normality (which is what we would like to have), but it helps. Another detail to take into account is that in big samples (>200 observations) normality is not such an issue. However, if we solve normality, we avoid a lot of other problems (e.g. heteroscedacity) so that's the main reason why we are doing this analysis.\n\n* **Homoscedasticity** - Homoscedasticity refers to the 'assumption that dependent variable(s) exhibit equal levels of variance across the range of predictor variable(s)' (Hair et al., 2013). Homoscedasticity is desirable because we want the error term to be the same across all values of the independent variables.\n\n* **Linearity** - The most common way to assess linearity is to examine scatter plots and search for linear patterns. If patterns are not linear, it would be worthwhile to explore data transformations. However, we'll not get into this because most of the scatter plots we've seen appear to have linear relationships.\n\n* **Absence of correlated errors** - Correlated errors, like the definition suggests, happen when one error is correlated to another. For instance, if one positive error makes a negative error systematically, it means that there's a relationship between these variables. This occurs often in time series, where some patterns are time related. We'll also not get into this. However, if you detect something, try to add a variable that can explain the effect you're getting. That's the most common solution for correlated errors.","metadata":{}},{"cell_type":"code","source":"# SalePrice\n\n# Normality\n\n# We'll do this paying attention to:\n\n# Histogram - Kurtosis and skewness.\n# Normal probability plot - Data distribution should closely \n# follow the diagonal that represents the normal distribution.\n\nsns.distplot(data['SalePrice'], fit=norm)\nfig = plt.figure()\nres = stats.probplot(data['SalePrice'], plot=plt)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"'SalePrice' is not normal. It shows 'peakedness', positive skewness and does not follow the diagonal line.\n\nA simple data transformation can solve the problem. This is one of the awesome things you can learn in statistical books: in case of positive skewness, log transformations usually works well.","metadata":{}},{"cell_type":"code","source":"data['SalePrice'] = np.log(data['SalePrice'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.distplot(data['SalePrice'], fit=norm)\nfig = plt.figure()\nres = stats.probplot(data['SalePrice'], plot=plt)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# GrLivArea\nsns.distplot(data['GrLivArea'], fit=norm)\nfig = plt.figure()\nres = stats.probplot(data['GrLivArea'], plot=plt)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# positive skewness","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['GrLivArea'] = np.log(data['GrLivArea'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.distplot(data['GrLivArea'], fit=norm)\nfig = plt.figure()\nres = stats.probplot(data['GrLivArea'], plot=plt)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# TotalBsmtSF\n\nsns.distplot(data['TotalBsmtSF'], fit=norm)\nfig = plt.figure()\nres = stats.probplot(data['TotalBsmtSF'], plot=plt)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"What do we have here?\n\n* Something that, in general, presents skewness.\n* A significant number of observations with value zero (houses without basement).\n* A big problem because the value zero doesn't allow us to do log transformations.\n\nTo apply a log transformation here, we'll create a variable that can get the effect of having or not having basement (binary variable). Then, we'll do a log transformation to all the non-zero observations, ignoring those with value zero. This way we can transform data, without losing the effect of having or not basement.","metadata":{}},{"cell_type":"code","source":"#create column for new variable (one is enough because it's a binary categorical feature)\n#if area>0 it gets 1, for area==0 it gets 0\ndata['HasBsmt'] = pd.Series(0, index=data.index)\ndata.loc[data['TotalBsmtSF']>0,'HasBsmt'] = 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['HasBsmt'].sample(40)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#transform data\ndata.loc[data['HasBsmt']==1, 'TotalBsmtSF'] = np.log(data['TotalBsmtSF'])\n\n#hence using the mask above has helped us to update values only \n#where TotalBsmtSF !=0, and the assignment has already taken care\n#to match the indexes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['TotalBsmtSF'][630]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.distplot(data[data['TotalBsmtSF']>0]['TotalBsmtSF'], fit=norm)\nfig = plt.figure()\nres = stats.probplot(data[data['TotalBsmtSF']>0]['TotalBsmtSF'], plot=plt)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Homoscedasticity","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The best approach to test homoscedasticity for two metric variables is graphically. Departures from an equal dispersion are shown by such shapes as cones (small dispersion at one side of the graph, large dispersion at the opposite side) or diamonds (a large number of points at the center of the distribution).","metadata":{}},{"cell_type":"code","source":"#scatter plot 'SalePrice' and 'GrLivArea'\nplt.scatter(data['GrLivArea'], data['SalePrice'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Older versions of this scatter plot (previous to log transformations), had a conic shape.\nAs you can see, the current scatter plot doesn't have a conic shape anymore. That's the power of normality! Just by ensuring normality in some variables, we solved the homoscedasticity problem.","metadata":{}},{"cell_type":"code","source":"plt.scatter(data[data['TotalBsmtSF']>0]['TotalBsmtSF'], data[data['TotalBsmtSF']>0]['SalePrice'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can say that, in general, 'SalePrice' exhibit equal levels of variance across the range of 'TotalBsmtSF'.","metadata":{}},{"cell_type":"code","source":"#dummy variables\n#convert categorical variable into dummy\n\ndata = pd.get_dummies(data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> ***Conclusion***\n\n","metadata":{}},{"cell_type":"markdown","source":"Throughout this kernel we put in practice many of the strategies proposed by [Hair et al. (2013)](http://amzn.to/2uC3j9p).\n\nWe philosophied about the variables, we analysed 'SalePrice' alone and with the most correlated variables, we dealt with missing data and outliers, we tested some of the fundamental statistical assumptions and we even transformed categorial variables into dummy variables.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**New things learnt**\n* sns.lmplot -> to plot scatter plot and reg line\n* sns.FacetGrid\n* If dealing with prices over years, prices should be constant prices\n* Multicolinearity -> several independent variables in a model are correlated\n* Conditions for multivariate analysis -> Normality, Homoscedasticity, Linearity, Absence of correlated errors\n* If positive skewness -> transformation used is log transformation","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}